---
layout: default 
title: Tao He's Homepage
---

		<div class="blurb">
			<h3>Ph.D. Candidate Tao He (何涛)</h3>
			<p><img src="1.jpg" alt="photo" style="width:190px;height:226px;float:left;margin-right:35px;">
				<ul class="contacts">
					<li>Faculty of Information Technology</li>
					<li>Monash University</li>
					<li> VIC, 3800, Australia </li>
					<li> <b>Email</b>: hetaoconquer@gmail.com </li>
					<li><a href="https://scholar.google.com/citations?user=nhbZOLcAAAAJ&hl=en"><div style="color:blue;"> Google Scholar</div></a></li>
					<li><a href="https://ht014.github.io/"><iv style="color:blue;">Personal Page </div> </a></li>
				</ul>
			</p>
			</div> 

<div class="about">
	
	<p>I am a third year Ph.D. student (sponsored by Monash's full scholarship) in the Faculty of Information Technology at Monash University in Australia, 
		working with the group of Data Science  under the supervision of <a = href="https://users.monash.edu.au/~yli/"><font color="#0000ff">Dr. Yuan-Fang Li</font></a>  and co-supervision with <a href="https://lianligao.github.io/"><font color="#0000ff">Prof. Lianli Gao</font>.</a>
	 &nbsp;
	I obtained my MS and BS degrees in Computer Science from The University of Electronic Science and Technology of China (UESTC)  under the supervision of <a href="https://scholar.google.com.au/citations?user=F5Zy9V4AAAAJ&hl=en"><font color="#0000ff">Prof. Jingkuan Song</font></a> in 2018,  and Northeast Normal University (NENU) in 2015, respectively.  </p>
	<p> My research ranges from  Machine Learning, Deep Learning, Computer Vision (Images and Videos), Hash and Quantisation, etc.  Specifically, I am mainly focusing on detecting  visual relationships from images. 

<h4> Recent News</h4>
<ul>
	<li>Starting my postdoc in the <a = href="https://www.monash.edu/it/dsai/vision-language"><strong> <font color="#0000ff">Vision and Language group </font></strong></a> from Feb. 2022.</li>
	<li>One paper accepted to <strong>TNNLS</strong> 2021 on network embedding</li>
	<li>One paper accepted to <strong>ICCV</strong> 2021 on Human-Ojbect interaction with scene graphs.</li>
	<li>One paper acccepted to <strong>IJCAI</strong> 2021 on scene graph generation.</li>
	<li>One paper accepted to <strong>AAAI</strong> 2020 on network quantisation.</li>
	<li>One paper acccepted to <strong>IJCV</strong> 2020 on image compression.</li>
	<li>One paper accepted to <strong>IJCAI</strong> 2019 on domain adaptive hash for images.</li>
	</ul>

<h4>Publications</h4>
<ul>
	<li><strong>Tao He</strong>, Lianli Gao, Jingkuan Song, Yuan-Fang Li. Exploiting Scene Graphs for Human-Object Interaction Detection. ICCV 2021.<a href=" " rel="nofollow"><font color="#0000ff">[code]</font></a> <a href="https://arxiv.org/abs/2108.08584" rel="nofollow"><font color="#0000ff">[paper]</font></a> <font color="#ff0000"><b>&nbsp;</b></font> </li>

	<li>Jingkuan Song, <strong>Tao He</strong>, Lianli Gao,  Alan Hanjalic, Hengtao Shen. Unified Binary Generative Adversarial Network for Image Retrieval and Compression. IJCV 2021.<a href="" rel="nofollow"><font color="#0000ff">[code]</font></a> <a href="http://pure.tudelft.nl/ws/files/82393102/ijcv2020_binary.pdf" rel="nofollow"><font color="#0000ff">[paper]</font></a> <font color="#ff0000"><b>&nbsp;</b></font> </li>

	<li><strong>Tao He</strong>, Lianli Gao, Jingkuan Song, Xing Wang, Ke Huang, Yuan-Fang Li. Sneq: Semi-supervised Attributed Network Embedding with Attention-based Quantisation. AAAI 2020.<a href=" " rel="nofollow"><font color="#0000ff">[code]</font></a> <a href=" " rel="nofollow"><font color="#0000ff">[paper]</font></a> <font color="#ff0000"><b>&nbsp;</b></font> </li>
	
	<li><strong>Tao He</strong>, Lianli Gao, Jingkuan Song, Jianfei Cai, Yuan-Fang Li. Learning from the scene and borrowing from the rich: Tackling the long tail in scene graph generation. IJCAI 2020.<a href=" " rel="nofollow"><font color="#0000ff">[code]</font></a> <a href=" " rel="nofollow"><font color="#0000ff">[paper]</font></a> <font color="#ff0000"><b>&nbsp;</b></font> </li>


	<li><strong>Tao He</strong>, Yuan-Fang Li, Lianli Gao, Dongxiang Zhang, Jingkuan Song. Learning from the scene and borrowing from the rich: Tackling the long tail in scene graph generation. IJCAI 2020.<a href=" " rel="nofollow"><font color="#0000ff">[code]</font></a> <a href=" " rel="nofollow"><font color="#0000ff">[paper]</font></a> <font color="#ff0000"><b>&nbsp;</b></font> </li>

	<li>Jingkuan Song, <strong>Tao He</strong>, Lainli Gao, Xing Xu, Hengtao Shen. Deep region hashing for efficient large-scale instance search from images. AAAI 2018.<a href=" " rel="nofollow"><font color="#0000ff">[code]</font></a> <a href=" " rel="nofollow"><font color="#0000ff">[paper]</font></a> <font color="#ff0000"><b>&nbsp;</b></font> </li>
	<li>Jingkuan Song, <strong>Tao He</strong>, Lainli Gao, Xing Xu, Alan Hanjalic, Hengtao Shen. Binary generative adversarial networks for image retrieval. AAAI 2018.<a href=" " rel="nofollow"><font color="#0000ff">[code]</font></a> <a href=" " rel="nofollow"><font color="#0000ff">[paper]</font></a> <font color="#ff0000"><b>&nbsp;</b></font> </li>

	<li>Jingkuan Song, <strong>Tao He</strong>, Hangbo Fan, Lianli Gao. Deep discrete hashing with self-supervised pairwise labels. ECML 2017.<a href=" " rel="nofollow"><font color="#0000ff">[code]</font></a> <a href=" " rel="nofollow"><font color="#0000ff">[paper]</font></a> <font color="#ff0000"><b>&nbsp;</b></font> </li>
	
	
</ul>

	
<h4> Acadamic Service </h4>
<ul>
	<li>As a reviewer for confereces: AAAI, ACMMM Asia, CIKM</li>
	<li>As a reviewer for journals: IJIS, FGCS</li>
	</ul>
</div>
