---
layout: default 
title: Tao He's Person Page
---

		<div class="blurb">
			<h3>PhD. Candidate Tao He (何涛)</h3>
			<p><img src="1.jpg" alt="photo" style="width:190px;height:226px;float:left;margin-right:35px;">
				<ul class="contacts">
					<li>Faculty of Information Technology</li>
					<li>Monash University</li>
					<li> VIC, 3800, Australia </li>
					<li> <b>Email</b>: hetaoconquer@gmail.com </li>
					<li><a href="https://scholar.google.com/citations?user=nhbZOLcAAAAJ&hl=en"><div style="color:blue;"> Google Scholar</div></a></li>
					<li><a href="https://ht014.github.io/"><iv style="color:blue;">Personal Page </div> </a></li>
				</ul>
			</p>
			</div> 

<div class="about">
	
	<p>I am a Third year PhD. student (sponsored by Monash's full scholarship) in the Faculty of Information Technology at Monash University in Australia, 
		working with the group of Data Science  under the supervision of <a = href="https://users.monash.edu.au/~yli/"><font color="#0000ff">Dr. Yuan-Fang Li</font></a>  and co-supervision with <a href="https://lianligao.github.io/"><font color="#0000ff">Prof. Lianli Gao</font>.</a>
	 &nbsp;
	I obtained my MS and BS degree in Computer Science from The University of Electronic Science and Technology of China (UESTC) in 2018, under the supervision of <a href="https://scholar.google.com.au/citations?user=F5Zy9V4AAAAJ&hl=en"><font color="#0000ff">Prof. Jingkuan Song</font></a>,  and Northeast Normal University in 2015, respectively.  </p>
	<p> My research ranges from  Machine Learning, Deep Learning, Computer Vision (Images and Videos), Hash and Quantisation, etc.  Specifically, I am mainly focusing on detecting  visual relationships from images. 

<h4> Recent News</h4>
<ul>
	<li>One paper submitted to TNNLS 2021.</li>
	<li>One paper accepted to <strong>ICCV 2021 </strong> on Human-Ojbect interaction with scene graphs.</li>
	<li>One paper acccepted to <strong>IJCAI 2021</strong> on scene graph generation.</li>
	<li>One paper accepted to <strong>AAAI 2020</strong> on network quantisation.</li>
	<li>One paper acccepted to <strong>IJCV 2020</strong> on scene graph generation.</li>
	<li>One paper accepted to <strong>IJCAI 2019</strong> on domain adaptive hash for image.</li>
	</ul>

<h4>Publications</h4>
<ul>
	<li><strong>Tao He</strong>, Lianli Gao, Jingkuan Song, Yuan-Fang Li. Exploiting Scene Graphs for Human-Object Interaction Detection. ICCV 2021.<a href=" " rel="nofollow"><font color="#0000ff">[code]</font></a> <a href="https://arxiv.org/abs/2108.08584" rel="nofollow"><font color="#0000ff">[paper]</font></a> <font color="#ff0000"><b>&nbsp;</b>Cora A*</font> </li>

	<li>Jingkuan Song, <strong>Tao He</strong>, Lianli Gao,  Alan Hanjalic, Hengtao Shen. Unified Binary Generative Adversarial Network for Image Retrieval and Compression. IJCV 2021.<a href="" rel="nofollow"><font color="#0000ff">[code]</font></a> <a href="http://pure.tudelft.nl/ws/files/82393102/ijcv2020_binary.pdf" rel="nofollow"><font color="#0000ff">[paper]</font></a> <font color="#ff0000"><b>&nbsp;</b>Cora A*</font> </li>

	<li><strong>Tao He</strong>, Lianli Gao, Jingkuan Song, Xing Wang, Ke Huang, Yuan-Fang Li. Sneq: Semi-supervised Attributed Network Embedding with Attention-based Quantisation. AAAI 2020.<a href=" " rel="nofollow"><font color="#0000ff">[code]</font></a> <a href=" " rel="nofollow"><font color="#0000ff">[paper]</font></a> <font color="#ff0000"><b>&nbsp;</b>Cora A*</font> </li>
	
	<li><strong>Tao He</strong>, Lianli Gao, Jingkuan Song, Jianfei Cai, Yuan-Fang Li. Learning from the scene and borrowing from the rich: Tackling the long tail in scene graph generation. IJCAI 2020.<a href=" " rel="nofollow"><font color="#0000ff">[code]</font></a> <a href=" " rel="nofollow"><font color="#0000ff">[paper]</font></a> <font color="#ff0000"><b>&nbsp;</b>Cora A*</font> </li>


	<li><strong>Tao He</strong>, Yuan-Fang Li, Lianli Gao, Dongxiang Zhang, Jingkuan Song. Learning from the scene and borrowing from the rich: Tackling the long tail in scene graph generation. IJCAI 2020.<a href=" " rel="nofollow"><font color="#0000ff">[code]</font></a> <a href=" " rel="nofollow"><font color="#0000ff">[paper]</font></a> <font color="#ff0000"><b>&nbsp;</b>Cora A*</font> </li>

	<li>Jingkuan Song, <strong>Tao He</strong>, Lainli Gao, Xing Xu, Hengtao Shen. Deep region hashing for efficient large-scale instance search from images. AAAI 2018.<a href=" " rel="nofollow"><font color="#0000ff">[code]</font></a> <a href=" " rel="nofollow"><font color="#0000ff">[paper]</font></a> <font color="#ff0000"><b>&nbsp;</b>Cora A*</font> </li>
	<li>Jingkuan Song, <strong>Tao He</strong>, Lainli Gao, Xing Xu, Alan Hanjalic, Hengtao Shen. Binary generative adversarial networks for image retrieval. AAAI 2018.<a href=" " rel="nofollow"><font color="#0000ff">[code]</font></a> <a href=" " rel="nofollow"><font color="#0000ff">[paper]</font></a> <font color="#ff0000"><b>&nbsp;</b>Cora A*</font> </li>

	<li>Jingkuan Song, <strong>Tao He</strong>, Hangbo Fan, Lianli Gao. Deep discrete hashing with self-supervised pairwise labels. ECML 2017.<a href=" " rel="nofollow"><font color="#0000ff">[code]</font></a> <a href=" " rel="nofollow"><font color="#0000ff">[paper]</font></a> <font color="#ff0000"><b>&nbsp;</b>Cora A</font> </li>
	
	
</ul>

	
<h4> Acadamic Service </h4>
<ul>
	<li>As a reviewer for confereces: AAAI, MM Asia, CIKM</li>
	<li>As a reviewer for journals: IJIS, FGCS</li>
	</ul>
</div>
